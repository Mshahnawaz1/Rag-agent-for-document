{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd28f7a4",
   "metadata": {},
   "source": [
    "Document extracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d82feb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"kafka.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9d958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "920c245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\",exist_ok=True)\n",
    "\n",
    "txtDir = \"../data/text_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "974cd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2cbdfcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/text_files\\kf100.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#save text into files\n",
    "def save_text(filepath, content):\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "        print(f\"Saved: {filepath}\")\n",
    "\n",
    "\n",
    "text = \"\".join(page.page_content for page in pages[100:150])\n",
    "text = preprocess_text(text)\n",
    "\n",
    "save_text(os.path.join(txtDir, \"kf100.txt\"), text)\n",
    "\n",
    "# for filepath, content in sample_texts.items():\n",
    "#     save_text(filepath, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\")\n",
    "document = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bbe44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first listened to him—it bored me silly. It\\'s only natural for someone your age. In time you\\'ll appreciate it. People soon get tired of things that aren\\'t boring, but not of what is boring. Go figure. For me, I might have the leisure to be bored, but not to grow tired of something. Most people can\\'t distinguish between the two.\"   \"You said you\\'re an unusual person. Do you mean because of the hemophilia?\"   \"That\\'s part of it,\" he says, and gives this devilish sort of smile. \"There\\'s more to it '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text\n",
    "\n",
    "text = preprocess_text(text)\n",
    "tex = text[0:500]\n",
    "tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2185aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=350,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2e974ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# 3.1 Initialize the Embedding Model\n",
    "# NOTE: The model and task type are crucial for retrieval accuracy.\n",
    "embedding = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",  # A strong general-purpose model\n",
    "    task_type=\"retrieval_document\" # Optimizes the embedding for document search\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c5528",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "The dot product of the embedded vectors shows the similarity between the words. \n",
    "Embeddings are created using a pretrained models. These models can be decided based on the use case of the similarity. we have bunch of models like openai , gemini embedding, hugging face also hasd some "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd5441b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972301896586312\n",
      "0.7972381759029037\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n",
    "\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n",
    "\n",
    "print(np.dot(embedding1, embedding2))  # Similarity between sentence1 and sentence2\n",
    "print(np.dot(embedding1, embedding3))  # Similarity between sentence1 and sentence  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = '../data/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3798f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load texts \n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "    \n",
    "loader = TextLoader(\"../data/text_files/kf100.txt\")\n",
    "texts = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43925c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = texts[0].page_content\n",
    "# t1 = preprocess_text(text)\n",
    "chunks = r_splitter.split_documents(texts)\n",
    "len(chunks)\n",
    "# chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dba8730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d77c9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `from_documents` method automatically handles the embedding and storage.\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embedding, \n",
    "    persist_directory=chroma_db\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "007614a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahn\\AppData\\Local\\Temp\\ipykernel_15968\\2976856195.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  v1 = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "embedding = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",  # A strong general-purpose model\n",
    "    task_type=\"retrieval_document\" # Optimizes the embedding for document search\n",
    ")\n",
    "v1 = Chroma(\n",
    "    persist_directory=chroma_db,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "print(v1._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U :class:`~langchain-chroma\n",
    "! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f21911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "got that impression.\"   I don't reply.   \"From my own experience, when someone is trying very hard to get something, they don't. And when they're running away from something as hard as they can, it usually catches up with them. I'm generalizing, of course.\"   \"If you generalize about me, then, what's in my future? If I'm seeking and running at the\n",
      "first listened to himâ€”it bored me silly. It's only natural for someone your age. In time you'll appreciate it. People soon get tired of things that aren't boring, but not of what is boring. Go figure. For me, I might have the leisure to be bored, but not to grow tired of something. Most people can't distinguish between the two.\"   \"You said\n",
      "on the record jacket of \"Kafka on the Shore.\" But there's one thing missing: that lovely, innocent smile. She still smiles from time to time, definitely a charming smile, but it's always limited somehow, a smile that never goes beyond the moment. A high, invisible wall surrounds her, holding people at arm's length. Every morning she drives her\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about kafka?\"\n",
    "docs_ss = v1.similarity_search(question,k=6)\n",
    "print(len(docs_ss))\n",
    "print(docs_ss[0].page_content)\n",
    "print(docs_ss[1].page_content)\n",
    "print(docs_ss[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cd33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dad9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
