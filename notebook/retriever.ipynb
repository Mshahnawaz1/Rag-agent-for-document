{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f212e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# 3.1 Initialize the Embedding Model\n",
    "# NOTE: The model and task type are crucial for retrieval accuracy.\n",
    "embedding = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",  # A strong general-purpose model\n",
    "    task_type=\"retrieval_document\" # Optimizes the embedding for document search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b8fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87624217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "v1 = Chroma(\n",
    "    persist_directory='../data/chroma/',\n",
    "    embedding_function=embedding\n",
    ")\n",
    "print(v1._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0502e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac26d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concept of time, as we understand it, is closely linked to the Big Bang. Scientists believe time itself began approximately 13.8 billion years ago with this cosmic expansion. Before this event, the very fabric of spacetime did not exist in its current form.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"User: {input}\n",
    "Make sure your renponse is concise and clear and do not exceed three sentences.\n",
    "\"\"\"\n",
    "\n",
    "class llmPipeline():\n",
    "    def __init__(self, model=\"gemini-2.5-flash\", prompt_template=template):\n",
    "        self.llm = ChatGoogleGenerativeAI(model=model)\n",
    "        self.prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def invoke(self, input_dict={}):\n",
    "        try:\n",
    "            response = self.chain.invoke(input_dict)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"API Test Failed. Ensure the GOOGLE_API_KEY is correctly set in your .env file. Error: {e}\"\n",
    "a = llmPipeline()\n",
    "\n",
    "result = a.invoke({\"input\": \"what is the beginign of time?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11247d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1de578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot summarize the context of the documents because no context was provided. Please provide the documents you would like me to summarize. I need the information to answer your question. thanks for asking!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "question = \"Summarize the context of the documents in three sentences.\"\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=v1.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874a2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot summarize the context as no documents or context were provided. Please provide the context you would like me to summarize. thanks for asking!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"..data/text_files/kf100\"\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7639ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Summarize the context of the documents in three sentences.',\n",
       " 'result': 'I cannot summarize the context of the documents because no context was provided. Please provide the documents you would like me to summarize. I need the information to answer your question. thanks for asking!',\n",
       " 'source_documents': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb3358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
